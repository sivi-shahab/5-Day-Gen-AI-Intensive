{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Create an Agent with Gemma 2 from Scratch\n\nIn this notebook, you will learn to build a functional agent using Gemma 2, a large language model proposed by Google. This comprehensive guide walks through the essential steps and provides hands-on examples to illustrate key concepts. Whether you are a beginner or an experienced developer, this notebook offers valuable insights into agent creation, from setting up the environment to implementing advanced features. The practical approach ensures that you gain a solid understanding of Gemma 2 and its applications in developing intelligent agents.","metadata":{}},{"cell_type":"markdown","source":"## References\n* https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/2/build-an-agent-from-scratch\n* [ReAct: Synergizing Reasoning and Acting in Language Models](https://react-lm.github.io)","metadata":{}},{"cell_type":"markdown","source":"## Setup and import Libraries","metadata":{}},{"cell_type":"code","source":"# !pip install --upgrade transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\nimport numpy as np\nimport pickle\nfrom huggingface_hub import snapshot_download, login\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\nfrom kaggle_secrets import UserSecretsClient\nprint(f\"Transformers Version: {transformers.__version__}\")\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:33:29.382251Z","iopub.execute_input":"2024-11-18T06:33:29.382571Z","iopub.status.idle":"2024-11-18T06:33:34.440164Z","shell.execute_reply.started":"2024-11-18T06:33:29.382538Z","shell.execute_reply":"2024-11-18T06:33:34.439107Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Transformers Version: 4.45.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load model","metadata":{}},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nHUGGING_FACE_TOKEN = user_secrets.get_secret(\"HUGGING_FACE_TOKEN\")\nlogin(token=HUGGING_FACE_TOKEN, add_to_git_credential=True)\ntokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-9b-it\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"google/gemma-2-9b-it\",\n    device_map=\"auto\",\n    torch_dtype=torch.bfloat16\n)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:33:42.364019Z","iopub.execute_input":"2024-11-18T06:33:42.365053Z","iopub.status.idle":"2024-11-18T06:42:23.638172Z","shell.execute_reply.started":"2024-11-18T06:33:42.365012Z","shell.execute_reply":"2024-11-18T06:42:23.637408Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Token is valid (permission: fineGrained).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03d870ed8efe4d20b4c37292daf35fdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c4bb11623ee4a75af96c340fdaba11a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52af699ea2eb42b1ae2f538a25f07f1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0597e0f4c1134cd39cbeee1908ba4233"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd1e344ac46e4cbab9a1d3f5b3b4688c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"976b9fc9465248a8a82d993561b9c4dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b64d87d53c62477fa8e22e1f4714689d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e0c837d05f049f18e70ab2782fc3e11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d16e5dd3c7a4e4cb69155eeac69e73e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86ceec406c06440abbff00ec8ff6b7d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a1a83c40ede4a16abc7c08aca3e2b7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"680a9a7b7fb947b1b9d00a918117d15e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cf5eba423c24b1a8faf5fdb79e07943"}},"metadata":{}},{"name":"stdout","text":"Gemma2ForCausalLM(\n  (model): Gemma2Model(\n    (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n    (layers): ModuleList(\n      (0-41): 42 x Gemma2DecoderLayer(\n        (self_attn): Gemma2Attention(\n          (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n          (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n          (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n          (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n          (rotary_emb): Gemma2RotaryEmbedding()\n        )\n        (mlp): Gemma2MLP(\n          (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n          (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n          (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n          (act_fn): PytorchGELUTanh()\n        )\n        (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n        (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n        (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n        (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n      )\n    )\n    (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n  )\n  (lm_head): Linear(in_features=3584, out_features=256000, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-9b-it\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Usage","metadata":{}},{"cell_type":"code","source":"messages = [\n    { \"role\": \"user\", \"content\": \"Write a hello world program\" },\n]\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\ninput_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\noutputs = model.generate(input_ids=input_ids, max_new_tokens=512)\nprint(tokenizer.decode(outputs[0]))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:43:07.856673Z","iopub.execute_input":"2024-11-18T06:43:07.857594Z","iopub.status.idle":"2024-11-18T06:43:34.227223Z","shell.execute_reply.started":"2024-11-18T06:43:07.857552Z","shell.execute_reply":"2024-11-18T06:43:34.226248Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"The 'max_batch_size' argument of HybridCache is deprecated and will be removed in v4.46. Use the more precisely named 'batch_size' argument instead.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"name":"stdout","text":"<bos><start_of_turn>user\nWrite a hello world program<end_of_turn>\n<start_of_turn>model\n```python\nprint(\"Hello, world!\")\n```\n\nThis program will print the text \"Hello, world!\" to the console. \n\nHere's how it works:\n\n* **`print()`** is a built-in function in Python that displays output to the console.\n* **`\"Hello, world!\"`** is a string literal, which is a sequence of characters enclosed in double quotes. This is the text that will be printed.\n\n\nLet me know if you'd like to see this program in a different programming language!<end_of_turn>\n<eos>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Implement a function that could chat with Gemma 2.","metadata":{}},{"cell_type":"code","source":"history = []\ndef chat(prompt):\n    history.append({ \"role\": \"user\", \"content\": prompt})\n    prompt = tokenizer.apply_chat_template(history, tokenize=False, add_generation_prompt=True)\n    input_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(input_ids=input_ids, max_new_tokens=512)\n    content = tokenizer.decode(outputs[0])\n    content = content.split(\"<start_of_turn>model\")[-1].replace(\"<end_of_turn>\", \"\").replace(\"<eos>\", \"\").strip(\"\\n\")\n    message = {\"role\": \"system\", \"content\": content}\n    history.append(message)\n    return message","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:44:36.034708Z","iopub.execute_input":"2024-11-18T06:44:36.035421Z","iopub.status.idle":"2024-11-18T06:44:36.042607Z","shell.execute_reply.started":"2024-11-18T06:44:36.035377Z","shell.execute_reply":"2024-11-18T06:44:36.041487Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Markdown\nmessage = chat(\"Hi, what is your name?\")\ndisplay(Markdown(message[\"content\"]))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:44:38.744767Z","iopub.execute_input":"2024-11-18T06:44:38.745143Z","iopub.status.idle":"2024-11-18T06:44:41.308201Z","shell.execute_reply.started":"2024-11-18T06:44:38.745107Z","shell.execute_reply":"2024-11-18T06:44:41.307188Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"My name is Gemma. I am an open-weights AI assistant."},"metadata":{}}]},{"cell_type":"code","source":"message = chat(\"My name is Lonnie, nice to meet you.\")\ndisplay(Markdown(message[\"content\"]))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:52:24.454165Z","iopub.execute_input":"2024-11-18T06:52:24.454960Z","iopub.status.idle":"2024-11-18T06:52:33.141436Z","shell.execute_reply.started":"2024-11-18T06:52:24.454918Z","shell.execute_reply":"2024-11-18T06:52:33.140545Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"It's nice to meet you too, Lonnie!  \n\nIs there anything else I can help you with today?"},"metadata":{}}]},{"cell_type":"code","source":"message = chat(\"Implement a hello world function using javascript.\")\ndisplay(Markdown(message[\"content\"]))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:44:48.066261Z","iopub.execute_input":"2024-11-18T06:44:48.067138Z","iopub.status.idle":"2024-11-18T06:45:21.307873Z","shell.execute_reply.started":"2024-11-18T06:44:48.067095Z","shell.execute_reply":"2024-11-18T06:45:21.306919Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"```javascript\nfunction helloWorld() {\n  console.log(\"Hello, world!\");\n}\n\nhelloWorld(); \n```\n\n**Explanation:**\n\n* **`function helloWorld() { ... }`**: This defines a function named `helloWorld`. Functions are blocks of code that perform a specific task.\n* **`console.log(\"Hello, world!\");`**: This line is inside the function. It uses `console.log` to print the text \"Hello, world!\" to the console (which is where you'll see the output in your browser's developer tools or in a terminal if you're running this code).\n* **`helloWorld();`**: This line *calls* the `helloWorld` function, which executes the code inside it and prints the message.\n\n**To run this code:**\n\n1. **Save it as a `.js` file** (e.g., `hello.js`).\n2. **Open your browser's developer console:** Usually, you can do this by pressing F12.\n3. **Go to the \"Console\" tab.**\n4. **Drag and drop the `.js` file into the console** or use the `console.log()` function to print the output.\n\n\n\nLet me know if you have any other questions!"},"metadata":{}}]},{"cell_type":"code","source":"message = chat(\"How about implementing a welcome page in StreamLit?\")\ndisplay(Markdown(message[\"content\"]))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:45:21.309559Z","iopub.execute_input":"2024-11-18T06:45:21.309869Z","iopub.status.idle":"2024-11-18T06:46:02.444297Z","shell.execute_reply.started":"2024-11-18T06:45:21.309836Z","shell.execute_reply":"2024-11-18T06:46:02.443418Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"```python\nimport streamlit as st\n\nst.title(\"Welcome to My Streamlit App!\")\n\nst.write(\"This is a simple welcome page.\")\n\nst.write(\"Explore more features by clicking the navigation bar.\")\n```\n\n**Explanation:**\n\n1. **Import Streamlit:** `import streamlit as st` imports the Streamlit library and gives it the alias `st` for easier use.\n\n2. **Set the Title:** `st.title(\"Welcome to My Streamlit App!\")` creates a large, centered title for your page.\n\n3. **Add Text:** `st.write(\"This is a simple welcome page.\")` displays a paragraph of text. You can use `st.write` for various data types like strings, lists, and even code.\n\n4. **Add a Call to Action:** `st.write(\"Explore more features by clicking the navigation bar.\")` encourages users to explore further.\n\n**To run this code:**\n\n1. **Make sure you have Streamlit installed:** `pip install streamlit`\n2. **Save the code as a `.py` file** (e.g., `app.py`).\n3. **Run the file from your terminal:** `streamlit run app.py`\n4. **Open your web browser** and go to the address shown in the terminal (usually `http://localhost:8501`).\n\nThis will open your Streamlit app with the welcome page.\n\n\n\nLet me know if you have any other questions or want to add more elements to your welcome page!"},"metadata":{}}]},{"cell_type":"markdown","source":"## Implement a React Agent","metadata":{}},{"cell_type":"code","source":"class Agent:\n    def __init__(self, system=\"\"):\n        self.system = system\n        self.messages = []\n        if self.system:\n            self.__call__(system)\n\n    def __call__(self, message):\n        self.messages.append({\"role\": \"user\", \"content\": message})\n        result = self.execute()\n        self.messages.append({\"role\": \"assistant\", \"content\": result})\n        return result\n\n    def execute(self):\n        prompt = tokenizer.apply_chat_template(self.messages, tokenize=False, add_generation_prompt=True)\n        input_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n        outputs = model.generate(input_ids=input_ids, max_new_tokens=512)\n        content = tokenizer.decode(outputs[0])\n        result = content.split(\"<start_of_turn>model\")[-1].replace(\"<end_of_turn>\", \"\").replace(\"<eos>\", \"\").strip(\"\\n\").strip(\" \")\n        return result","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:46:02.445645Z","iopub.execute_input":"2024-11-18T06:46:02.446037Z","iopub.status.idle":"2024-11-18T06:46:02.454832Z","shell.execute_reply.started":"2024-11-18T06:46:02.445992Z","shell.execute_reply":"2024-11-18T06:46:02.453937Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"prompt = \"\"\"\nYou run in a loop of Thought, Action, PAUSE, Observation.\nAt the end of the loop you output an Answer\nUse Thought to describe your thoughts about the question you have been asked.\nUse Action to run one of the actions available to you - then return PAUSE.\nObservation will be the result of running those actions.\n\nYour available actions are:\n\ncalculate:\ne.g. calculate: 4 * 7 / 3\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n\naverage_dog_weight:\ne.g. average_dog_weight: Collie\nreturns average weight of a dog when given the breed\n\nExample session:\n\nQuestion: How much does a Bulldog weigh?\nThought: I should look the dogs weight using average_dog_weight\nAction: average_dog_weight: Bulldog\nPAUSE\n\nYou will be called again with this:\n\nObservation: A Bulldog weights 51 lbs\n\nYou then output:\n\nAnswer: A bulldog weights 51 lbs\n\"\"\".strip()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:53:23.261935Z","iopub.execute_input":"2024-11-18T06:53:23.262711Z","iopub.status.idle":"2024-11-18T06:53:23.267664Z","shell.execute_reply.started":"2024-11-18T06:53:23.262667Z","shell.execute_reply":"2024-11-18T06:53:23.266704Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def calculate(what):\n    return eval(what)\n\ndef average_dog_weight(name):\n    if name in \"Scottish Terrier\": \n        return(\"Scottish Terriers average 20 lbs\")\n    elif name in \"Border Collie\":\n        return(\"a Border Collies average weight is 37 lbs\")\n    elif name in \"Toy Poodle\":\n        return(\"a toy poodles average weight is 7 lbs\")\n    else:\n        return(\"An average dog weights 50 lbs\")\n\nknown_actions = {\n    \"calculate\": calculate,\n    \"average_dog_weight\": average_dog_weight\n}","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:53:26.603684Z","iopub.execute_input":"2024-11-18T06:53:26.604520Z","iopub.status.idle":"2024-11-18T06:53:26.610037Z","shell.execute_reply.started":"2024-11-18T06:53:26.604479Z","shell.execute_reply":"2024-11-18T06:53:26.609119Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"agent = Agent(prompt)\nresult = agent(\"How much does a toy poodle weigh?\")\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:54:42.949931Z","iopub.execute_input":"2024-11-18T06:54:42.950310Z","iopub.status.idle":"2024-11-18T06:54:53.913246Z","shell.execute_reply.started":"2024-11-18T06:54:42.950275Z","shell.execute_reply":"2024-11-18T06:54:53.912315Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Thought: I should look up the average weight of a toy poodle using the average_dog_weight action. \nAction: average_dog_weight: Toy Poodle\nPAUSE\n","output_type":"stream"}]},{"cell_type":"code","source":"result = average_dog_weight(\"Toy Poodle\")\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:54:53.915148Z","iopub.execute_input":"2024-11-18T06:54:53.915842Z","iopub.status.idle":"2024-11-18T06:54:53.920689Z","shell.execute_reply.started":"2024-11-18T06:54:53.915794Z","shell.execute_reply":"2024-11-18T06:54:53.919736Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"a toy poodles average weight is 7 lbs\n","output_type":"stream"}]},{"cell_type":"code","source":"next_prompt = \"Observation: {}\".format(result)\nagent(next_prompt)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:54:53.921819Z","iopub.execute_input":"2024-11-18T06:54:53.922150Z","iopub.status.idle":"2024-11-18T06:54:58.653323Z","shell.execute_reply.started":"2024-11-18T06:54:53.922102Z","shell.execute_reply":"2024-11-18T06:54:58.652389Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"Answer: A toy poodle's average weight is 7 lbs.\""},"metadata":{}}]},{"cell_type":"code","source":"display(agent.messages)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:55:01.877210Z","iopub.execute_input":"2024-11-18T06:55:01.877900Z","iopub.status.idle":"2024-11-18T06:55:01.884104Z","shell.execute_reply.started":"2024-11-18T06:55:01.877858Z","shell.execute_reply":"2024-11-18T06:55:01.883226Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"[{'role': 'user',\n  'content': 'You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\naverage_dog_weight:\\ne.g. average_dog_weight: Collie\\nreturns average weight of a dog when given the breed\\n\\nExample session:\\n\\nQuestion: How much does a Bulldog weigh?\\nThought: I should look the dogs weight using average_dog_weight\\nAction: average_dog_weight: Bulldog\\nPAUSE\\n\\nYou will be called again with this:\\n\\nObservation: A Bulldog weights 51 lbs\\n\\nYou then output:\\n\\nAnswer: A bulldog weights 51 lbs'},\n {'role': 'assistant',\n  'content': \"Okay, I understand the process. I'm ready for a question!\"},\n {'role': 'user', 'content': 'How much does a toy poodle weigh?'},\n {'role': 'assistant',\n  'content': 'Thought: I should look up the average weight of a toy poodle using the average_dog_weight action. \\nAction: average_dog_weight: Toy Poodle\\nPAUSE'},\n {'role': 'user',\n  'content': 'Observation: a toy poodles average weight is 7 lbs'},\n {'role': 'assistant',\n  'content': \"Answer: A toy poodle's average weight is 7 lbs.\"}]"},"metadata":{}}]},{"cell_type":"code","source":"agent = Agent(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:55:04.916224Z","iopub.execute_input":"2024-11-18T06:55:04.917110Z","iopub.status.idle":"2024-11-18T06:55:09.005830Z","shell.execute_reply.started":"2024-11-18T06:55:04.917064Z","shell.execute_reply":"2024-11-18T06:55:09.004970Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\nWhat is their combined weight\"\"\"\nprint(agent(question))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:55:09.007237Z","iopub.execute_input":"2024-11-18T06:55:09.007599Z","iopub.status.idle":"2024-11-18T06:55:15.379612Z","shell.execute_reply.started":"2024-11-18T06:55:09.007564Z","shell.execute_reply":"2024-11-18T06:55:15.378670Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Thought: I need to find the average weight of each breed and then add them together. \nAction: average_dog_weight: Border Collie\nPAUSE\n","output_type":"stream"}]},{"cell_type":"code","source":"next_prompt = \"Observation: {}\".format(average_dog_weight(\"Border Collie\"))\nprint(next_prompt)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:55:15.381437Z","iopub.execute_input":"2024-11-18T06:55:15.382136Z","iopub.status.idle":"2024-11-18T06:55:15.386924Z","shell.execute_reply.started":"2024-11-18T06:55:15.382087Z","shell.execute_reply":"2024-11-18T06:55:15.386038Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Observation: a Border Collies average weight is 37 lbs\n","output_type":"stream"}]},{"cell_type":"code","source":"print(agent(next_prompt))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:55:15.388154Z","iopub.execute_input":"2024-11-18T06:55:15.388621Z","iopub.status.idle":"2024-11-18T06:55:22.803683Z","shell.execute_reply.started":"2024-11-18T06:55:15.388577Z","shell.execute_reply":"2024-11-18T06:55:22.802399Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Thought: Now I need the average weight of a Scottish Terrier and then add it to the Border Collie's weight.\nAction: average_dog_weight: Scottish Terrier\nPAUSE\n","output_type":"stream"}]},{"cell_type":"code","source":"next_prompt = \"Observation: {}\".format(eval(\"37 + 20\"))\nprint(next_prompt)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:55:22.806298Z","iopub.execute_input":"2024-11-18T06:55:22.806662Z","iopub.status.idle":"2024-11-18T06:55:22.811856Z","shell.execute_reply.started":"2024-11-18T06:55:22.806628Z","shell.execute_reply":"2024-11-18T06:55:22.810896Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Observation: 57\n","output_type":"stream"}]},{"cell_type":"code","source":"agent(next_prompt)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:55:22.812989Z","iopub.execute_input":"2024-11-18T06:55:22.813274Z","iopub.status.idle":"2024-11-18T06:55:29.233217Z","shell.execute_reply.started":"2024-11-18T06:55:22.813230Z","shell.execute_reply":"2024-11-18T06:55:29.232313Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'Thought:  Okay, now I add the two weights together.\\nAction: calculate: 37 + 57\\nPAUSE'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Action","metadata":{}},{"cell_type":"code","source":"import re\naction_re = re.compile('^Action: (\\w+): (.*)$')   # python regular expression to selection action\ndef query(question, max_turns=5):\n    i = 0\n    bot = Agent(prompt)\n    next_prompt = question\n    while i < max_turns:\n        i += 1\n        result = bot(next_prompt)\n        print(result)\n        actions = [\n            action_re.match(a) \n            for a in result.split('\\n') \n            if action_re.match(a)\n        ]\n        if actions:\n            # There is an action to run\n            action, action_input = actions[0].groups()\n            if action not in known_actions:\n                raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n            print(\" -- running {} {}\".format(action, action_input))\n            observation = known_actions[action](action_input)\n            print(\"Observation:\", observation)\n            next_prompt = \"Observation: {}\".format(observation)\n        else:\n            return","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:55:29.234184Z","iopub.execute_input":"2024-11-18T06:55:29.234499Z","iopub.status.idle":"2024-11-18T06:55:29.245212Z","shell.execute_reply.started":"2024-11-18T06:55:29.234465Z","shell.execute_reply":"2024-11-18T06:55:29.244377Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\nWhat is their combined weight\"\"\"\nquery(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:55:29.246418Z","iopub.execute_input":"2024-11-18T06:55:29.246716Z","iopub.status.idle":"2024-11-18T06:55:59.466959Z","shell.execute_reply.started":"2024-11-18T06:55:29.246685Z","shell.execute_reply":"2024-11-18T06:55:59.466060Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Thought: I need to find the average weight of each breed and then add them together. \nAction: average_dog_weight: Border Collie\nPAUSE\n -- running average_dog_weight Border Collie\nObservation: a Border Collies average weight is 37 lbs\nThought: Now I need the average weight of a Scottish Terrier and then add it to the Border Collie's weight.\nAction: average_dog_weight: Scottish Terrier\nPAUSE\n -- running average_dog_weight Scottish Terrier\nObservation: Scottish Terriers average 20 lbs\nThought:  Time to add the weights together.\nAction: calculate: 37 + 20 \nPAUSE\n -- running calculate 37 + 20 \nObservation: 57\nAnswer: The combined weight of a Border Collie and a Scottish Terrier is 57 lbs.\n","output_type":"stream"}]},{"cell_type":"code","source":"question = \"\"\"Calculate 3 * 88 + 99\"\"\"\nquery(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:55:59.469688Z","iopub.execute_input":"2024-11-18T06:55:59.470157Z","iopub.status.idle":"2024-11-18T06:56:14.775597Z","shell.execute_reply.started":"2024-11-18T06:55:59.470111Z","shell.execute_reply":"2024-11-18T06:56:14.774701Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Thought: To get the answer, I need to multiply 3 by 88 and then add 99. \n\nAction: calculate: 3 * 88 + 99\nPAUSE\n -- running calculate 3 * 88 + 99\nObservation: 363\nAnswer: 363\n","output_type":"stream"}]},{"cell_type":"code","source":"question = \"\"\"Do you know the result of 99 * 88 + 1289?\"\"\"\nquery(question)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T06:56:31.070477Z","iopub.execute_input":"2024-11-18T06:56:31.070804Z","iopub.status.idle":"2024-11-18T06:56:47.257562Z","shell.execute_reply.started":"2024-11-18T06:56:31.070770Z","shell.execute_reply":"2024-11-18T06:56:47.256600Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Thought: I can calculate that using the 'calculate' action. \nAction: calculate: 99 * 88 + 1289\nPAUSE\n -- running calculate 99 * 88 + 1289\nObservation: 10001\nAnswer: 99 * 88 + 1289 = 10001\n","output_type":"stream"}]}]}